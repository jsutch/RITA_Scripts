{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "\n",
    " We want to extend the insights that Zeek and RITA are giving us about the probable sketchiness of particular connections. The goal in this notebook is to explain the data analysis in a way that other, more fluid, tools can be built. \n",
    " \n",
    "\n",
    " \n",
    "**RITAs statistical analysis plus locally gathered heuristics**   \n",
    " RITA and Zeek are fantastic tools to explore traffic and narrow down bad actors but published blacklists are always laggy and incomplete, when they work and are supported. Also - the scoring doesn't filter for items like DNS or other probable-good services (or call them out), which adds to the SecOps response time to filter.  Here we can bring some low-cost tools to bear and some local understanding to narrow down what to invest time into, good or bad.\n",
    "\n",
    "\n",
    "Some methods we're using:\n",
    "- Combine Beacons and Conns files to identify unique talkers\n",
    "- retrieve BGP Autonomous Systems info to identify originators (or listeners) in Wild West areas\n",
    "\n",
    "also - are we getting connections from nets that practice good hygiene? \n",
    "- does an ip have a DNS entry?\n",
    "- does an ip have a PTR record?\n",
    "\n",
    "What local tools can add dimension?\n",
    "- was the sender identified as malicious by other means? (fail2ban ICMP type 3 returns)\n",
    "\n",
    "\n",
    "Unfortunately these blacklists don't work anymore:\n",
    "- MalwareDomains.com\n",
    "- MalwareDomainList.com\n",
    "- malware-domains.com\n",
    "\n",
    "Fresher Blacklist providers (as of 8/2021):\n",
    "- https://urlhaus.abuse.ch/downloads/csv/\n",
    "- https://github.com/curbengh/urlhaus-filter\n",
    "- https://github.com/StevenBlack/hosts\n",
    "- https://www.abuseipdb.com\n",
    "\n",
    "\n",
    "### running this with your own data:\n",
    "- run the rita_extractor.sh to get your data\n",
    "- put the records where the \"load data\" cell (should be \\#4) can find them.\n",
    "- you probably want to generate your own \"beaconish_asns\" file:\n",
    "    - this is currently looking for a file in the records dir called 'beaconish_asns'. You can make your own with:\n",
    "    ```\n",
    "    df[(df['Score'] >.80)]['asn_desc']\n",
    "    ```\n",
    "    - scan the list to make sure that good services (like DNS, prometheus, etc) are srubbed\n",
    "    - replace the contents of records/beaconish_asns with that output. If you put it anywhere else a function will break. \n",
    "- check the metadata sections for metadata lists. Heads up: the functions work with their own metadata lists. Changing the data in the cells won't change the way the functions operate. \n",
    "- If you want to publish you may want to use the obscureips script. \n",
    "\n",
    "\n",
    "\n",
    "**Home and Home Office Networks**  \n",
    "I have a separate notebook for this that needs to be updated for the latest changes. I'll remove this when it's published.\n",
    "You may want to analyze office or home net traffic and find out chatty corporate tools. You can add your own, but this will add a score to tag \"friendly surveillance\" from Apple, Google, et al. My lists are US-Centric - tailor to your locale. These may or may not be things you want in your custom RITA blacklist, but you may not know what they are yet. \n",
    "\n",
    "\n",
    "\n",
    "TODOs: \n",
    "- building this in a framework\n",
    "- summarize outputs as a report (that could be used to kick off tickets, or add to a log)\n",
    "- auto export the ranking to an API or datastore that other apps could use\n",
    "- make the heuristics modular such that we can trivially import n-number of blacklists, etc\n",
    "- add thread/async to dns/ptr lookups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Viz imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Config matplotlib\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = True # in matplotlib, edge borders are turned off by default.\n",
    "sns.set_style(\"darkgrid\") # set a grey grid as a background\n",
    "\n",
    "# turn off warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import datetime as datetime\n",
    "import time\n",
    "\n",
    "# ip/AS lookup tools\n",
    "import socket\n",
    "from ipwhois import IPWhois\n",
    "from ipwhois.net import Net\n",
    "from ipwhois.asn import IPASN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions imports\n",
    "from functions.functions import iplookup, getAsInfo, is_sketchy, is_corp, is_sketchy_provider, isip, has_dns, has_ptr, f2b_marked, in_blacklist, tally_total, total_score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metadata\n",
    "\n",
    "**functions calling these lists are replicated in the functions/functions.py file.**\n",
    "\n",
    "The items are left here for clarity, but if you change them here the functions won't notice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AS-SONICTELECOM,', 'ASIANET', 'ASN-SPIN,', 'ASN-WINDTRE', 'BAIDU']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define corporate target AS Descriptors\n",
    "invasive_corps = ['AMAZON','APPLE','GOOGLE','MICROSOFT','CLOUDFLARENET','SALESFORCE','AKAMAI','OPENDNS']\n",
    "# define countries with lax enforcement\n",
    "sketchy_countries = ['CN','RU','VN','HK','TW','IN','BR','RO','HU','KR','IT','UG','TR','MY','BO','CO']\n",
    "# define ISPs with lax enforcement\n",
    "sketchy_providers = []\n",
    "providers = open('records/beaconish_asns','r').readlines()\n",
    "for p in providers:\n",
    "    sketchy_providers.append(p.split()[0])\n",
    "#\n",
    "sketchy_providers[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data\n",
    "\n",
    "this takes the output of rita show-long-connections (dfconns) and rita show-beacons (dfbeacons).\n",
    "\n",
    "The obscured IPs must be the same for each file - we merge the two on a matched ipsrc->ipdst key. The df will fail to create if there is nothing to merge on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbeacons = pd.read_csv('records/scrubbed_ext_20210315062437_beacons.csv')\n",
    "dfconns = pd.read_csv('records/scrubbed_ext_20210315062437_longconns.csv')\n",
    "#dfdns = pd.read_csv('dns.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfconns['ConnString'] = dfconns['Source IP'] + '->' + dfconns['Destination IP']\n",
    "dfbeacons['ConnString'] = dfbeacons['Source IP'] + '->'+ dfbeacons['Destination IP']\n",
    "df = pd.merge(dfbeacons, dfconns, on=['ConnString'], how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**clean up merge data**\n",
    "\n",
    "since the merge key is an amagalm of connection to connection strings, the Source IP and Destination IP collision columns _x and _y should be erroneous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['Source IP_y']\n",
    "del df['Destination IP_y']\n",
    "df.rename(columns={\"Destination IP_x\": \"Destination IP\",'Source IP_x':'Source IP'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Score', 'Source IP', 'Destination IP', 'Connections', 'Avg Bytes',\n",
       "       'Intvl Range', 'Size Range', 'Top Intvl', 'Top Size', 'Top Intvl Count',\n",
       "       'Top Size Count', 'Intvl Skew', 'Size Skew', 'Intvl Dispersion',\n",
       "       'Size Dispersion', 'ConnString', 'Port:Protocol:Service', 'Duration'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing the IP sets\n",
    "\n",
    "Basic data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique localhosts\n",
    "len(df['Source IP'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['65.254.18.118', '104.153.105.82', '192.168.23.89',\n",
       "       '49.235.37.144', '42.192.234.75', '45.119.126.59', '120.70.98.132',\n",
       "       '61.221.64.5', '202.95.14.159', '190.210.182.179',\n",
       "       '106.124.131.214', '157.131.240.195', '49.232.39.21',\n",
       "       '211.219.18.186', '123.206.90.149', '190.85.94.106',\n",
       "       '49.233.77.12', '114.219.157.97', '210.178.94.227',\n",
       "       '118.212.146.30', '106.75.61.147', '129.211.119.202',\n",
       "       '35.220.253.166', '119.45.177.219', '125.5.180.84',\n",
       "       '134.175.111.215', '134.209.41.198', '189.110.163.26',\n",
       "       '116.228.233.91', '190.171.133.10', '144.91.70.164',\n",
       "       '101.89.213.84', '118.98.96.184', '64.64.227.224',\n",
       "       '222.168.18.227', '103.10.87.54', '203.195.207.85',\n",
       "       '121.4.111.232', '101.36.127.150', '2.196.193.181',\n",
       "       '123.127.244.100', '121.241.244.92', '182.254.149.130',\n",
       "       '81.68.243.13', '106.124.142.64', '1.220.185.149', '123.30.149.34',\n",
       "       '103.55.62.78', '118.24.121.227', '120.92.166.166',\n",
       "       '121.4.138.185', '49.235.29.185', '140.249.222.242',\n",
       "       '121.5.60.195', '96.69.13.140', '220.164.250.31', '180.95.183.214',\n",
       "       '97.113.95.12', '195.29.102.42', '201.151.6.30', '111.231.54.33',\n",
       "       '206.189.140.87', '61.155.209.51', '101.231.146.36',\n",
       "       '164.132.56.243', '186.101.233.58', '51.91.111.73',\n",
       "       '106.124.139.161', '106.12.205.149', '61.177.125.242',\n",
       "       '124.239.148.87', '115.159.157.154', '106.12.215.238',\n",
       "       '175.24.185.31', '81.68.216.53', '152.32.226.205',\n",
       "       '183.232.250.154', '123.58.216.197', '81.68.217.130',\n",
       "       '118.89.160.141', '36.155.9.139', '59.148.18.42', '129.211.167.38',\n",
       "       '119.45.215.155', '121.4.91.59', '81.69.25.239', '152.136.133.117',\n",
       "       '159.75.43.3', '139.199.4.191', '122.114.75.180', '119.45.178.210',\n",
       "       '81.71.47.214', '51.38.88.139', '118.25.63.170', '81.68.193.31',\n",
       "       '111.229.235.119', '94.154.1.103', '111.229.237.32',\n",
       "       '94.23.253.21', '42.193.116.130', '113.53.238.195', '192.99.6.226',\n",
       "       '185.206.118.62', '119.45.177.140', '119.29.91.228',\n",
       "       '81.70.222.231', '81.161.63.253', '81.70.92.101', '141.98.80.85',\n",
       "       '81.161.63.103', '81.161.63.251', '195.54.160.250',\n",
       "       '45.93.201.193', '120.92.79.133', '118.70.233.206',\n",
       "       '205.185.125.54'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Source IP'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique targets\n",
    "len(df['Destination IP'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "754"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique connections\n",
    "len(df['ConnString'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding AS info\n",
    "\n",
    "If you're reading this notebook I'm guessing that you probably already know what BGP is and get why we're grading  data in this way. If not, read on:\n",
    "\n",
    "**Quick BGP/AS intro (stolen liberally from Cloudflare's great tutorial):**  \n",
    "The *Border Gateway Protocol (BGP)* is the postal service of the Internet. To manage these endpoints each network broken into smaller networks known as *Autonomous systems (AS)*. Each of these networks is essentially a large pool of routers run by a single organization. \n",
    "\n",
    "If we continue to think of BGP as the postal service of the Internet, ASâ€™s are like individual post office branches. A town may have hundreds of mailboxes, but the mail in those boxes must go through the local postal branch before being routed to another destination. The internal routers within an AS are like mailboxes, they forward their outbound transmissions to the AS, which then uses BGP routing to get these transmissions to their destinations.\n",
    "\n",
    "To get on the Internet you need an IP Block, which needs a BGP AS. The companies that own the AS are responsible for the traffic that goes through them. If you have a lot of bad traffic coming from one server in an AS then there's reason to believe that blocks in other IP space controlled by that AS are also probably poorly managed. \n",
    "\n",
    "**Grading traffic from a particular AS block**  \n",
    "This may be part of a decision to drop traffic coming from a single server or from the entire IP space as a Network Admin, but in this context we're simply going to grade traffic to that AS as more suspicious.\n",
    "\n",
    "**Grading traffic coming from a Country**\n",
    "Each BGP area is controlled within a Region, which then distributes to countries who have laws regarding internet traffic, hacking, etc. Some countries are more permissive than others with regard to hacking, fraud and spam. While it's incorrect and unfair to grade the citizens or services of a country based on the worst of their netizens, it's reasonable to grade countries with overly promiscuous (or non-existent) laws about hacking higher for further review. \n",
    "\n",
    "**Grading traffic coming from a Company**  \n",
    "Much of the same rules apply here - if a company has a policy for their devices to send tracking data home through your networks you should be able to know about it. If they have lax policies concerning network access or services that could host C2 or bad traffic, you should be able to know about that, too. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add ASN columns\n",
    "\n",
    "takes a little time for the lookups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**loop through and add AS fields**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdata = ['asn','asn_cidr','asn_country','asn_desc']\n",
    "for a in asdata:\n",
    "    df[a] =  df[['Source IP','Destination IP']].apply(getAsInfo,category=a,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**how many are unique?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['asn'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['46887', '14586', '204428', '45090', '132203', '14061', '4134',\n",
       "       '28361', '64050', '9498'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['asn'].unique()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['asn_country'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'BG', 'CN', 'BR', 'SG', 'IN', 'MY', 'HK', 'RU', 'ES', 'CO',\n",
       "       'TH', 'AU', 'ID', 'FR', 'CA', 'GB', 'PA', 'VN', 'HR', 'KR', 'BO',\n",
       "       'TW', 'AR', 'VE', 'PH', 'SC', 'IT', 'PE', 'SV', 'TR', 'JP', 'PT',\n",
       "       'MX', 'ZA', 'NG', 'CL', 'GT', 'DE', 'TN', 'MN', 'BY', 'IR', 'PS',\n",
       "       'SE', 'PK', 'NL', 'CH', 'LA', 'MM', 'PL', 'KE', 'BE', 'EC', '',\n",
       "       'IS', 'GR', 'EG'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['asn_country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = df['asn_country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asn    asn_desc                                                                    Source IP    \n",
       "45090  CNNIC-TENCENT-NET-AP Shenzhen Tencent Computer Systems Company Limited, CN  192.168.23.89    173\n",
       "14061  DIGITALOCEAN-ASN, US                                                        192.168.23.89     91\n",
       "4134   CHINANET-BACKBONE No.31,Jin-rong Street, CN                                 192.168.23.89     33\n",
       "16276  OVH, FR                                                                     192.168.23.89     26\n",
       "56046  CMNET-JIANGSU-AP China Mobile communications corporation, CN                192.168.23.89     15\n",
       "                                                                                                   ... \n",
       "27699  TELEFONICA BRASIL S.A, BR                                                   192.168.23.89      1\n",
       "27843  OPTICAL TECHNOLOGIES S.A.C., PE                                             192.168.23.89      1\n",
       "27882  Telefonica Celular de Bolivia S.A., BO                                      192.168.23.89      1\n",
       "27895  Nucleo S.A., PY                                                             192.168.23.89      1\n",
       "38511  TACHYON-AS-ID PT Remala Abadi, ID                                           192.168.23.89      1\n",
       "Length: 297, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['asn','asn_desc','Source IP']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add AS Features\n",
    "\n",
    " Add booleans if the connection is either a known invasive tech company or in the sketchy country list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sketchy'] = df['asn_country'].apply(is_sketchy)\n",
    "df['iscorp'] = df['asn_desc'].apply(is_corp)\n",
    "df['sketchy_provider'] = df['asn_desc'].apply(is_sketchy_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network sanity\n",
    "\n",
    "Are DNS/Reverse protocols handled in a friendly way?\n",
    "\n",
    "- reverse pointers\n",
    "- DNS entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  hostname lookups\n",
    "\n",
    "Not only is this helpful to get an eyeball sense of where streams are going, it gives you a good idea of what doesn't have a name. \n",
    "\n",
    "**This takes awhile**\n",
    "\n",
    "Garbage connections often don't have a DNS record. The timeout process makes this table take awhile to build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Source Name'] = df['Source IP'].apply(iplookup)\n",
    "df['Destination Name'] = df['Destination IP'].apply(iplookup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Source Name'].apply(isip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['src_ptr'] = df['Source Name'].apply(has_ptr)\n",
    "df['dst_ptr'] = df['Destination Name'].apply(has_ptr)\n",
    "df['src_dns'] = df['Source Name'].apply(has_dns)\n",
    "df['dst_dns'] = df['Destination Name'].apply(has_dns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**did we miss any?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weird entry - whois returns the AS info, but no description or prefix\n",
    "# AS      | IP               | BGP Prefix          | CC | Registry | Allocated  | AS Name\n",
    "# NA      | 69.195.171.128   | NA                  | US | arin     | 2017-09-18 | NA\n",
    "# From Hurricane Electric - Twitter:\n",
    "# AS13414 IRR Valid 69.195.171.0/24 Twitter Inc.\n",
    "df[df['asn'] == 'NA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for fail2ban entries\n",
    "\n",
    "https://www.fail2ban.org/wiki/index.php/Main_Page\n",
    "\n",
    "If you aren't familiar, fail2ban scans log files (e.g. /var/log/apache/error_log) and bans IPs that show malicious signs -- too many password failures, seeking for exploits, etc. If something hammers the logs enough to trigger a fail2ban entry this adds suspicion to the originating connection. \n",
    "\n",
    "A return of ICMP 3 (unreachable) means that the host was caught by fail2ban so we can filter on that from the logs.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we show the unique protocols available in our test\n",
    "len(df['Port:Protocol:Service'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and here's a count of which protocols are represented in our sample\n",
    "df['Port:Protocol:Service'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#services = {'icmp':3,'ssh':22,'smtp':25,'dns':53,'ssl':443,'http':80}\n",
    "services = ['icmp','ssh','smtp','dns','ssl','http']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple match list\n",
    "# [s for s in my_list if any(xs in s for xs in matchers)] # greedy - returns too much\n",
    "# {s for s in my_list for xs in matchers if xs in s}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add fail2ban hit feature\n",
    "df['fail2ban'] = df['Port:Protocol:Service'].apply(f2b_marked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some simple aggregated term analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sketchy is false\n",
    "df[~df['sketchy']][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connections flagged by fail2ban with no DNS entry\n",
    "df[(~df['dst_dns'])&(df['fail2ban'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracts using the flags\n",
    "\n",
    "Now we can use pandas and the features to test the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all providers where connection has no dst_ptr or dst_dns and has a fail2ban hit\n",
    "df[(~df['dst_ptr'])&(~df['dst_dns']) &(df['fail2ban'])].asn_desc.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the value of the asn_desc where the item not sketchy\n",
    "df[(~df['sketchy']) & (~df['src_dns'])][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(~df['sketchy']) &(df['fail2ban'])][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what AS regions get the most traffic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['asn','asn_desc','Source IP']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['asn','asn_desc','Source IP']][:11].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe the stats\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Score'].mean().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean duration in ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Duration'].mean().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "relative item correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### adding a heatmap to the correlation\n",
    "\n",
    "This data doesn't have corporate returns or ASs from the sketchy provider map. \n",
    "TODO: sort out sketchy providers from the data at the start of the definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= plt.figure(figsize=(15,8))\n",
    "sns.heatmap(df.corr(), linewidths=.1, linecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adding viz and stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most prevalent AS Numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['asn'][:30].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where are they coming from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['asn_desc'][:30].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What countries account for the most traffic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['asn_country'][:10].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a correlation between average bytes and number of connections?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Avg Bytes','Connections']][:10].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**whats the relative occurrance of high beacon traffic?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about the occurrange of high beaconish traffic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Score']][:30].plot(y='Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**how about long duration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['Duration'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### how about services?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The highest hits is fail2ban attempting to quash traffic, so we'll remove the ICMP entries\n",
    "df[~df['Port:Protocol:Service'].str.contains('icmp')]['Port:Protocol:Service'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Beaconish Originators\n",
    "\n",
    "What are the AS originators with over 80% beacon traffic and what country are they from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Score'] >.80)][3:]['asn_desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['asn_country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A slightly deeper dive into Chinese traffic\n",
    "df[df['asn_country'] =='CN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### connections where duration value is short and beaconish is high\n",
    "\n",
    "- only get low duration connections which exhibit above %75 beaconism \n",
    "\n",
    "In this case, there a bunch of ICMP messages originating from my host heading to (mostly) China. If fail2ban wasn't running this might be cause for further investigation, but fail2ban sends ICMP type 3 packets to an originator when it gets jailed. We're catching this upstream in the fail2ban column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the relative duration statistics?\n",
    "df['Duration'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the relative score distribution?\n",
    "df['Score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at raw duration length values\n",
    "df['Duration'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start drilling down**\n",
    "\n",
    "Find the mean of all the Duration values. Use the Mean to determine how ordinary the duration of the traffic is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Duration'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show only durations below the mean\n",
    "df[df['Duration'] < df['Duration'].mean()][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**what are connections where duration is below a particular quantile?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Duration'] < df['Duration'].quantile(.2)][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about where the duration is less than the .2 quantile, but with scores higher than 75%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df[(df['Duration'] < df['Duration'].quantile(.2)) & (df['Score'] > .75)]))\n",
    "df[(df['Duration'] < df['Duration'].quantile(.2)) & (df['Score'] > .75)][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**if anything is left originating to an external host that's not fail2ban there is something to dig further into**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if anything is left that's not fail2ban there is something to dig further into\n",
    "df[(df['Duration'] < df['Duration'].quantile(.2)) & (df['Score'] > .75)&(~df['fail2ban']) & (df['Destination IP'] != '192.168.23.89') ][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**is anything not originating from my ip?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is anything not originating from my ip?\n",
    "df[(df['Duration'] < df['Duration'].quantile(.2)) & (df['Score'] > .75)]['Source IP'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**look at only non-fail2ban items where Duration is in the upper quantile, Score is greater than .75 and originates from my server**\n",
    "\n",
    "Nothing in this batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at only non-fail2ban items where Duration is in the upper quantile, Score is greater than .75 and originates from my server\n",
    "# nothing here - so it looks like beaconish activity here is fail2ban related (handled by )\n",
    "df[(df['Duration'] < df['Duration'].quantile(.2)) & (df['Score'] > .75)& (~df['fail2ban']) &(df['Source IP'].str.contains('192.168.23.89'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Duration'] < df['Duration'].quantile(.2)) & (df['Score'] > .75)&(df['Source IP'] != '192.168.23.89')][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**where are ssh connections coming/going?**\n",
    "\n",
    "everything appears to be incoming, so we aren't launching any attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where are ssh connections coming/going?\n",
    "# everything appears to be incoming, so we aren't launching any attacks\n",
    "df[(df['Port:Protocol:Service'].str.contains('ssh')) & (df['Source IP'] != \"10.4.86.55\")]['ConnString'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**show all unique source names with scores above 80%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all unique source names with scores above 80%\n",
    "df[df['Score']> .8]['Source Name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blacklists\n",
    "\n",
    "Adding a blacklist heuristic. Most of rita-bl seems borked right now (stale data, backends offline, etc). In the meantime, lets get visibility using the spamhaus data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing a custom, line-delimited list\n",
    "blacklistraw = open('../records/20210827154850_blacklisted_ips.txt','r').readlines()\n",
    "blacklist = [x.strip('\\n') for x in blacklistraw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add feature\n",
    "df['blacklisted'] = df['Destination IP'].apply(in_blacklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are there any hits?\n",
    "df[df['blacklisted']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristics \n",
    "#### show the tally points\n",
    "\n",
    "Here we want to score based on the conditions. Some things are bad if they're True (sketchy TLD like Russia or China) some are bad if they're False (no reverse_ptr). Scoring needs a scale: some things are inherently worse (domain is the source of an attack in the wild) and some are not (reverse DNS).\n",
    "\n",
    "reasons to believe the traffic is not good (this could use expansion)\n",
    "sketchy - if True (the connection is from a poorly managed country tld) add 3\n",
    "fail2ban - if True (domain is spawning attacks in the wild) add 3\n",
    "sketchy_provider - if True then bad - add 3\n",
    "\n",
    "formal laziness: \n",
    "src_ptr - if they are the source and his is false, then bad 2\n",
    "dst_ptr - if they are the dst and it is false, then bad 2\n",
    "src_dns - if they are the source and his is false, then bad 2\n",
    "dst_dns - if they are the dst and it is false, then bad 2\n",
    "\n",
    "corporate canaries:\n",
    "iscorp - corporate canaries (apple, google, microsoft, etc). If true, then bad (though probably harmless). 1  \n",
    "\n",
    "\n",
    "\n",
    "so what I need is:\n",
    "- a feature that lets me know if src/dst is important for ptr and dns\n",
    "- a function that returns the value if the feature is present for each item and then tallies a score to be added as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're tallying on these columns\n",
    "df[['sketchy','src_ptr','dst_ptr','iscorp','sketchy_provider','src_dns','dst_dns','fail2ban', 'blacklisted']][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using tally_total\n",
    "df[['bscore','asn','sketchy','src_ptr','dst_ptr','iscorp','sketchy_provider','src_dns','dst_dns','fail2ban','blacklisted']][:10].apply(tally_total,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**adding heuristics score (bscore)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full scoring\n",
    "# using tally_total\n",
    "df['bscore'] = df[['bscore','asn','sketchy','src_ptr','dst_ptr','iscorp','sketchy_provider','src_dns','dst_dns','fail2ban','blacklisted']].apply(tally_total,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now create a total score\n",
    "\n",
    "Now to make the single value that represents RITA's statistical analysis score ('Score') and our heuristical score ('bscore'). For the moment it seems that Score * bscore is useful because Score is a Percentage which should scale the raw heuristical tally nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Score','bscore']][:10].apply(total_score,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create the new feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_score'] = df[['Score','bscore']].apply(total_score,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sort the list by total score \n",
    "\n",
    "Non-corp connections should bubble up and we should only be grading on bad actors and malware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:10].sort_values(by='total_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['bscore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['total_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Score','bscore', 'total_score','Source Name', 'Destination Name', 'Connections', 'Avg Bytes','asn_desc','asn_country']].sort_values(by='total_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final correlation\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final heatmap\n",
    "fig= plt.figure(figsize=(15,8))\n",
    "sns.heatmap(df.corr(), linewidths=.1, linecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final\n",
    "\n",
    "And that's the basic process. I want to be able to scan through connections at least daily, then export the outputs to a datastore or to reporting for followup.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
